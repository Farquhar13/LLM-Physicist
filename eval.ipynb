{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92395445",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/llm-physicist/lib/python3.13/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Fine-tune Llama-3.2-1B-Instruct on physics Q&A (veggiebird/physics-scienceqa)\n",
    "Demonstrates pre- and post-fine-tuning outputs using LoRA (CPU-friendly).\n",
    "Includes quantitative evaluation (Exact Match + ROUGE-L) and sample outputs.\n",
    "\"\"\"\n",
    "\n",
    "import evaluate\n",
    "from datasets import load_dataset\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, TrainingArguments, Trainer\n",
    "from peft import LoraConfig, get_peft_model\n",
    "import evaluate\n",
    "import numpy as np\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2ba91a17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Evaluating base model ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Exact Match': np.float64(0.0), 'ROUGE-L': np.float64(0.19500464778163873)}\n",
      "\n",
      "Starting fine-tuning...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/llm-physicist/lib/python3.13/site-packages/torch/utils/data/dataloader.py:683: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='200' max='200' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [200/200 07:11, Epoch 1/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>3.122800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>0.771700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>0.497300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>0.455800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.345200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>0.346500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>0.311000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>0.312300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>0.251200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.235400</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Evaluating fine-tuned model ===\n",
      "{'Exact Match': np.float64(0.0), 'ROUGE-L': np.float64(0.24878891647512597)}\n",
      "\n",
      "=== Fine-tuned model sample outputs ===\n",
      "\n",
      "Q: What is the second law of thermodynamics?\n",
      "A: What is the second law of thermodynamics? The second law of thermodynamics is a statement about the direction of spontaneous processes. The law states that it is impossible to build a machine that can convert all the heat energy put into it into useful work. In other words, the heat energy from a machine will always be lost. This law applies to any spontaneous process.\n",
      "\n",
      "Q: Explain Newton's third law of motion.\n",
      "A: Explain Newton's third law of motion. Describe how the law applies to everyday life.\n",
      "Newton's third law states that for every force, there is an equal and opposite force. This means that when you push on someone or something, the person or thing pushes back on you with the same force. Imagine pushing a friend's hand. The hand pushes back on your hand with the same force. The hand is pushing on you with a force that is equal in magnitude and direction to the force you applied to it.\n",
      "The third law applies to everyday life in many ways. For example, if you push on a wall, the wall pushes on you with a force of equal magnitude. The wall is pushing on you with a force that is equal in magnitude and direction to the force you applied to it. This means that the wall is not going to fall over or push you away. The wall is just going to push back on you with the same force.\n",
      "The third law also applies to the forces that act on objects in the Earth's atmosphere.\n",
      "\n",
      "Q: What happens to time near the speed of light?\n",
      "A: What happens to time near the speed of light? The speed of light is a fundamental constant in physics. It is the fastest speed at which any object or information can travel. If you are moving at a speed greater than the speed of light, you will experience time dilation. Time dilation occurs when you are moving at a speed greater than the speed of light relative to an observer. The observer will measure time passing slower for you. This effect is very small at low speeds, but it becomes significant at high speeds.\n",
      "According to the theory of relativity, time dilation is a consequence of the speed of light. The closer you are to the speed of light, the slower time will pass for you relative to other observers. This means that time will pass slower for you relative to other observers. Time dilation is a predicted effect by Albert Einstein and is a key feature of his theory of special relativity.\n",
      "If you are moving at a speed greater than the speed of light, you will experience time dilation. The closer you are to the speed of light,\n"
     ]
    }
   ],
   "source": [
    "# -------------------------------\n",
    "# 1. Load base model + tokenizer\n",
    "# -------------------------------\n",
    "\n",
    "model_name = \"meta-llama/Llama-3.2-1B-Instruct\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "tokenizer.pad_token_id = tokenizer.eos_token_id\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_name,\n",
    "    device_map=\"cpu\"  # CPU-only; fine for 1B LoRA demo\n",
    ")\n",
    "\n",
    "# -------------------------------\n",
    "# 2. Load and format dataset\n",
    "# -------------------------------\n",
    "\n",
    "raw_ds = load_dataset(\"veggiebird/physics-scienceqa\", split=\"train\")\n",
    "\n",
    "# Convert to Q/A format\n",
    "def format_batch(batch):\n",
    "    return {\n",
    "        \"text\": [\n",
    "            f\"Question: {q}\\nAnswer: {a}\"\n",
    "            for q, a in zip(batch[\"input\"], batch[\"output\"])\n",
    "        ]\n",
    "    }\n",
    "\n",
    "formatted_ds = raw_ds.map(format_batch, batched=True)\n",
    "\n",
    "# Tokenize with labels\n",
    "def tokenize(batch):\n",
    "    enc = tokenizer(batch[\"text\"], truncation=True, padding=\"max_length\", max_length=256)\n",
    "    enc[\"labels\"] = enc[\"input_ids\"].copy()\n",
    "    return enc\n",
    "\n",
    "tokenized_ds = formatted_ds.map(tokenize, batched=True)\n",
    "\n",
    "# Split train/test\n",
    "split = tokenized_ds.train_test_split(test_size=0.1, seed=42)\n",
    "train_ds = split[\"train\"]\n",
    "test_ds = split[\"test\"]\n",
    "\n",
    "# -------------------------------\n",
    "# 3. Evaluation utilities\n",
    "# -------------------------------\n",
    "\n",
    "# Exact Match\n",
    "def exact_match(pred, ref):\n",
    "    return 1 if pred.strip().lower() == ref.strip().lower() else 0\n",
    "\n",
    "# ROUGE-L\n",
    "rouge_metric = evaluate.load(\"rouge\")\n",
    "\n",
    "def evaluate_model(model, tokenizer, dataset, n_samples=50): # increase n_samples later\n",
    "    em_scores = []\n",
    "    rouge_scores = []\n",
    "    subset = dataset.shuffle(seed=42).select(range(min(n_samples, len(dataset))))\n",
    "\n",
    "    for ex in subset:\n",
    "        # Extract Q/A from formatted text\n",
    "        question = ex[\"text\"].split(\"\\nAnswer:\")[0].replace(\"Question: \", \"\")\n",
    "        true_answer = ex[\"text\"].split(\"\\nAnswer:\")[1]\n",
    "\n",
    "        # Generate prediction\n",
    "        inputs = tokenizer(question, return_tensors=\"pt\").to(model.device)\n",
    "        outputs = model.generate(**inputs, max_new_tokens=100, pad_token_id=tokenizer.eos_token_id)\n",
    "        pred_answer = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "\n",
    "        # Metrics\n",
    "        em_scores.append(exact_match(pred_answer, true_answer))\n",
    "        rouge_result = rouge_metric.compute(predictions=[pred_answer], references=[true_answer])\n",
    "        rouge_scores.append(rouge_result[\"rougeL\"])\n",
    "\n",
    "    return {\n",
    "        \"Exact Match\": np.mean(em_scores),\n",
    "        \"ROUGE-L\": np.mean(rouge_scores)\n",
    "    }\n",
    "\n",
    "# -------------------------------\n",
    "# 4. Pre-fine-tune evaluation\n",
    "# -------------------------------\n",
    "\n",
    "print(\"\\n=== Evaluating base model ===\")\n",
    "base_metrics = evaluate_model(model, tokenizer, test_ds)\n",
    "print(base_metrics)\n",
    "\n",
    "# -------------------------------\n",
    "# 5. Apply LoRA adapter\n",
    "# -------------------------------\n",
    "\n",
    "lora_config = LoraConfig(\n",
    "    r=8,\n",
    "    lora_alpha=16,\n",
    "    lora_dropout=0.1,\n",
    "    task_type=\"CAUSAL_LM\"\n",
    ")\n",
    "model = get_peft_model(model, lora_config)\n",
    "\n",
    "# -------------------------------\n",
    "# 6. Fine-tuning\n",
    "# -------------------------------\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./llama1b-phys-scienceqa\",\n",
    "    per_device_train_batch_size=1,\n",
    "    gradient_accumulation_steps=4,\n",
    "    warmup_steps=10,\n",
    "    max_steps=200,       # originall 200, moving down for testing\n",
    "    learning_rate=2e-4,\n",
    "    logging_steps=20,\n",
    "    save_strategy=\"no\"\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_ds\n",
    ")\n",
    "\n",
    "print(\"\\nStarting fine-tuning...\")\n",
    "trainer.train()\n",
    "\n",
    "# -------------------------------\n",
    "# 7. Post-fine-tune evaluation\n",
    "# -------------------------------\n",
    "\n",
    "print(\"\\n=== Evaluating fine-tuned model ===\")\n",
    "ft_metrics = evaluate_model(model, tokenizer, test_ds)\n",
    "print(ft_metrics)\n",
    "\n",
    "# -------------------------------\n",
    "# 8. Qualitative sample outputs\n",
    "# -------------------------------\n",
    "\n",
    "sample_questions = [\n",
    "    \"What is the second law of thermodynamics?\",\n",
    "    \"Explain Newton's third law of motion.\",\n",
    "    \"What happens to time near the speed of light?\"\n",
    "]\n",
    "\n",
    "print(\"\\n=== Fine-tuned model sample outputs ===\")\n",
    "for q in sample_questions:\n",
    "    inputs = tokenizer(q, return_tensors=\"pt\").to(model.device)\n",
    "    outputs = model.generate(**inputs, max_new_tokens=200, pad_token_id=tokenizer.eos_token_id)\n",
    "    print(f\"\\nQ: {q}\\nA: {tokenizer.decode(outputs[0], skip_special_tokens=True)}\")\n",
    "\n",
    "# -------------------------------\n",
    "# 9. (Optional) Save adapter\n",
    "# -------------------------------\n",
    "# model.save_pretrained(\"./llama1b-phys-scienceqa-adapter\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "38535d25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Evaluating base model ===\n",
      "{'Exact Match': np.float64(0.0), 'ROUGE-L': np.float64(0.2644144734209732)}\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n=== Evaluating base model ===\")\n",
    "base_metrics = evaluate_model(model, tokenizer, test_ds)\n",
    "print(base_metrics)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2d712685",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Evaluating fine-tuned model ===\n",
      "{'Exact Match': np.float64(0.0), 'ROUGE-L': np.float64(0.24828817930383196)}\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n=== Evaluating fine-tuned model ===\")\n",
    "ft_metrics = evaluate_model(model, tokenizer, test_ds)\n",
    "print(ft_metrics)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm-physicist",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
